<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ARNOLD: A Benchmark for Language-Grounded Task Learning With Continuous States in Realistic 3D Scenes">
  <meta name="keywords" content="Benchmark, Language Grounding, Manipulation, Realistic, Continuous States">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ARNOLD</title>

<!-- Add icon library -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
<style>
.btn {
  background-color: Gray;
  border: none;
  color: white;
  padding: 12px 16px;
  font-size: 16px;
  cursor: pointer;
}

.is-rounded {border-radius: 12px;}

/* Darker background on mouse-over */
.btn:hover {
  background-color: Silver;
}

a {
	color: inherit;
    text-decoration: none;
}

.centered {
  text-align: center;
}

.publication-video {
  position: relative;
  width: 100%;
  height: 0;
  padding-bottom: 56.25%;

  overflow: hidden;
  border-radius: 10px !important;
}

.publication-video iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
}

</style>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.5/css/bulma.min.css">
<script src="https://kit.fontawesome.com/b25d0fd750.js" crossorigin="anonymous"></script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

<script>
function UpdateTaskIllustration() {
  var task = document.getElementById("illu-task").value;
  console.log("illu", task)
  var img = document.getElementById("task-illustration");
  img.src = "assets/" + "illu-" + task + ".png"
}

function UpdateTaskDemonstration() {
  var task = document.getElementById("demo-task").value;
  console.log("demo", task)
  var video = document.getElementById("task-demonstration");
  video.src = "assets/" + "demo-" + task + ".mp4"
  video.playbackRate = 1.75;
  video.play();
}
</script>

</head>

<body onload="UpdateTaskIllustration(); UpdateTaskDemonstration();">

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">ARNOLD: A Benchmark for Language-Grounded Task Learning With Continuous States in Realistic 3D Scenes</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a target="_blank" href="https://nikepupu.github.io/">Ran Gong</a><sup>1✶</sup>,</span>
            <span class="author-block">
              <a target="_blank" href="https://huangjy-pku.github.io/">Jiangyong Huang</a><sup>2,5✶</sup>,</span>
            <span class="author-block">
              <a target="_blank" href="https://www.zyz.lol/app/aboutme/aboutme.html">Yizhou Zhao</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="https://geng-haoran.github.io/">Haoran Geng</a><sup>2,5</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="https://xfgao.github.io/">Xiaofeng Gao</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="https://qywu.github.io/">Qingyang Wu</a><sup>4</sup>,
            </span>
            <br/>
            <span class="author-block">
              <a target="_blank" href="https://wensi-ai.github.io/">Wensi Ai</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="https://www.linkedin.com/in/josephziheng/">Ziheng Zhou</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="http://web.cs.ucla.edu/~dt/">Demetri Terzopoulos</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="http://www.stat.ucla.edu/~sczhu/">Song-Chun Zhu</a><sup>2,3,5</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="https://buzz-beater.github.io/">Baoxiong Jia</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a target="_blank" href="https://siyuanhuang.com/">Siyuan Huang</a><sup>5</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, Los Angeles,</span>
            <span class="author-block"><sup>2</sup>Peking University,</span>
            <span class="author-block"><sup>3</sup>Tsinghua University,</span>
            <br/>
            <span class="author-block"><sup>4</sup>Columbia University,</span>
            <span class="author-block"><sup>5</sup>National Key Laboratory of General Artificial Intelligence, BIGAI</span>
          </div>

          <p style="font-size: 0.9em; padding: 0.5em 0 0 0;">✶ indicates equal contribution</p>

          <div class="column has-text-centered">
            <div class="publication-links">
            <!-- Arxiv Link. -->
            <span class="link-block">
              <a target="_blank" href="placeholder"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>

            <!-- Code Link. -->
            <span class="link-block">
              <a target="_blank" href="https://github.com/arnold-benchmark/arnold"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
            </span>

            <!-- Video Link. -->
            <span class="link-block">
              <a target="_blank" href="https://youtu.be/w-Cp1PRDWzI"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-youtube"></i>
                </span>
                <span>Video</span>
              </a>
            </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser" style="margin-top: -5rem;">
  <div class="container is-fullhd">
    <div class="hero-body">
      <div class="container">
        <div class="has-text-centered" style="padding: 0 1em;">
          <img src="assets/teaser.png"/>
          <p style="text-align: justify; font-size: 0.8em;">We present <tt>ARNOLD</tt>, a benchmark that evaluates <b>language-grounded</b> task learning with <span style="color: #2176FF;"><b>continuous states</b></span> in <b>realistic 3D scenes</b>. <tt>ARNOLD</tt> provides 8 tasks with their demonstrations for learning and a testbed for the generalization abilities of agents over (1) <span style="color: #DB3A34;"><b>novel goal states</b></span>, (2) <span style="color: #963484;"><b>novel objects</b></span>, and (3) <span style="color: #1AA260;"><b>novel scenes</b></span>.</p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="margin-top: -4rem;">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Understanding the continuous states of objects is essential for task learning and planning in the real world. However, most existing task learning benchmarks assume discrete (<i>e.g.</i>, binary) object goal states, which poses challenges for the learning of complex tasks and transferring learned policy from simulated environments to the real world. Furthermore, state discretization limits a robot's ability to follow human instructions based on the grounding of actions and states. To tackle these challenges, we present <tt>ARNOLD</tt>, a benchmark that evaluates language-grounded task learning with continuous states in realistic 3D scenes. <tt>ARNOLD</tt> is comprised of 8 language-conditioned tasks that involve understanding object states and learning policies for continuous goals. To promote language-instructed learning, we provide expert demonstrations with template-generated language descriptions. We assess task performance by utilizing the latest language-conditioned policy learning models. Our results indicate that current models for language-conditioned manipulations continue to experience significant challenges in novel goal-state generalizations, scene generalizations, and object generalizations. These findings highlight the need to develop new algorithms that address this gap and underscore the potential for further research in this area.
          </p>
        </div>
      </div>
    </div>
    <br>
    <br>
    <!--/ Abstract. -->

  </div>

  <!-- Paper video. -->
  <div class="columns is-centered has-text-centered" style="margin-top: -3rem;">
    <div class="column is-two-thirds">
      <h2 class="title is-3">Video</h2>
      <div class="publication-video">
        <iframe src="https://www.youtube.com/embed/w-Cp1PRDWzI" frameborder="0" allow="autoplay; encrypted-media; picture-in-picture" allowfullscreen></iframe>
      </div>
    </div>
  </div>

</section>

<section class="section">
  <div class="container is-max-widescreen">

    <div class="rows">

    <!-- Animation. -->
    <div class="rows is-centered ">
      <div class="row is-full-width">
        <!-- Interpolating. -->
        <h3 class="title is-4">Summary</h3>
        <div class="content has-text-justified">
        <!-- <br> -->
        </div>
        <p>
          We highlight the following major points: (1) <tt>ARNOLD</tt> is built on <b>NVIDIA Isaac Sim</b>, equipped with <b>photo-realistic</b> and <b>physically-accurate</b> simulation, covering <b>40 distinctive objects</b> and <b>20 scenes</b>. (2) <tt>ARNOLD</tt> is comprised of <b>8 language-conditioned tasks</b> that involve understanding object states and learning policies for continuous goals. For each task, there are <b>7 data splits</b> including <i>i.i.d.</i> evaluation and <b>unseen generalization</b>. (3) <tt>ARNOLD</tt> provides <b>10k expert demonstrations</b> with diverse template-generated language instructions, based on thousands of human annotations. (4) We assess the task performances of the latest language-conditioned policy learning models. The results indicate that current models for language-conditioned manipulation <b>still struggle in understanding continuous states and producing precise motion control</b>. We hope these findings can foster future research to address the unsolved challenges in <b>instruction grounding</b> and <b>precise continuous motion control</b>.
        </p>
        <br/>
        <br/>

        <h3 class="title is-4">Comparison</h3>
        <div class="has-text-centered" style="padding: 0em;">
          <p style="text-align: justify; font-size: 0.8em;"><tt>ARNOLD</tt> features continuous robot control over continuous object states with a large
            number of demonstrations in photo-realistic scenes. Each task in <tt>ARNOLD</tt> is specified by a natural language instruction. <tt>ARNOLD</tt> also
            leverages advanced physics simulations powered by PhysX 5.0 to simulate articulated bodies and fluids. <b>Language</b>: Task goals are specified
            by natural language instruction. <b>Multi-Camera</b>: Robot is equipped with multiple cameras. <sup>1</sup>: A number of tasks in Maniskill use ground
            truth semantic segmentation as input. <b>Fluid</b>: Advanced fluid simulation. <b>Physics</b>: Realistic physics simulation with realistic grasping.
            <sup>2</sup>: RLbench-based benchmarks use simplified grasping. <b>Continuous</b>: Object state and goal state are continuous. <b>Scene</b>: Tasks are performed
            with a realistic scene background. <b>Robot</b>: Perform actions with real robots for all tasks. <b>R</b>: Rasterization. <b>RT</b>: RayTracing. <b>Flexible
            Material</b>: Easy to change materials and textures. <b>Generalization</b>: Systematic generalization test at different levels. Note that although
            Maniskill shows 3D scenes in their illustration figure, they do not include 3D scenes in their benchmark.</p>
          <br/>
          <img src="assets/comparison.png"/>
        </div>
        <br/>
        <br/>

        <h3 class="title is-4">Simulation Environment</h3>
        <div style="display:flex;">
          <div style="width:60%;">
            <p><tt>ARNOLD</tt> is built on <a target="_blank" href="https://developer.nvidia.com/isaac-sim">Isaac Sim</a>, featuring photo-realistic and physically-accurate simulation.
              The photo-realistic rendering is powered by GPU-enabled ray tracing, and the physics simulation is based on PhysX 5.0.
              In <tt>ARNOLD</tt>, we assign physics parameters (<i>e.g.</i>, friction, surface tension) to objects, including rigid-body objects and fluids.
              <tt>ARNOLD</tt> covers 40 distinct objects and 20 diverse scenes. The scenes are curated from <a target="_blank" href="https://tianchi.aliyun.com/specials/promotion/alibaba-3d-scene-dataset">3D-FRONT</a>.
              The objects come from <a target="_blank" href="https://developer.nvidia.com/isaac-sim">Isaac Sim</a>, <a target="_blank" href="https://ai2thor.allenai.org/">AI2-THOR</a>, <a target="_blank" href="https://sapien.ucsd.edu/">SAPIEN</a>.
              To enhance visual realism, we modified object meshes, <i>e.g.</i>, by modifying materials and adding top covers to drawers and cabinets.
              For more stable physics-based grasping, we performed convex decomposition to create precise collision proxies for each object.
              We use a 7-DoF Franka Emika Panda manipulator with a parallel gripper in <tt>ARNOLD</tt> for task execution.
              There are 5 cameras around the robot to provide visual inputs.
              We show an example of camera rendering, and visualize objects/scenes as follows.
            </p>
          </div>

          <div style="width:5%; display:flex; justify-content:center; align-items:center;">
          </div>

          <div style="width:30%; display:flex; justify-content:center; align-items:center;">
            <img src="assets/multi_view.png" alt="Multi-view cameras">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns">
        <div class="column is-half">
          <video poster="" id="scene1" autoplay muted loop height="100%">
            <source src="assets/scene_1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-half">
          <video poster="" id="scene2" autoplay muted loop height="100%">
            <source src="assets/scene_2.mp4" type="video/mp4">
          </video>
        </div>
      </div>

      <div class="columns">
        <div class="column is-half">
          <video poster="" id="scene3" autoplay muted loop height="100%">
            <source src="assets/scene_3.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-half">
          <video poster="" id="scene4" autoplay muted loop height="100%">
            <source src="assets/scene_4.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns">
        <div class="column is-half">
          <video poster="" id="object1" autoplay muted loop height="100%">
            <source src="assets/bottle.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-half">
          <video poster="" id="object2" autoplay muted loop height="100%">
            <source src="assets/drawer.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="columns">
        <div class="column is-half">
          <video poster="" id="object3" autoplay muted loop height="100%">
            <source src="assets/cabinet.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-half">
          <video poster="" id="object4" autoplay muted loop height="100%">
            <source src="assets/cup.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-widescreen">
    <div class="rows">
    <div class="rows is-centered ">
      <div class="row is-full-width">
        <h3 class="title is-4">Task</h3>
        <div style="display:flex;">
          <div style="width:50%;">
            <p><tt>ARNOLD</tt> contains 8 tasks with various goal state varitions.
              To succeed, the robot has to manipulate to maintain the object state within a continuous range around the goal state for a while.
              Accomplishing these tasks requires capabilities in language grounding, friction-based
              grasping, continuous state understanding, and precise robot motion control.
            </p>
          </div>

          <div style="width:5%; display:flex; justify-content:center; align-items:center;">
          </div>

          <div style="width:40%; display:flex; justify-content:center; align-items:center;">
            <img src="assets/tasks.png" alt="Task overview">
          </div>
        </div>
        
        <div class="column has-text-centered" style="margin-top: 1rem;">
        Illustration of task 
          <div class="select is-small">     
            <select id="illu-task" onchange="UpdateTaskIllustration()">
            <option value="pickup_object" selected="selected">Pickup Object</option>
            <option value="reorient_object">Reorient Object</option>
            <option value="open_drawer">Open Drawer</option>
            <option value="close_drawer">Close Drawer</option>
            <option value="open_cabinet">Open Cabinet</option>
            <option value="close_cabinet">Close Cabinet</option>
            <option value="pour_water">Pour Water</option>
            <option value="transfer_water">Transfer Water</option>
            </select>
          </div>
          <br/>
          <br/>

          <img id="task-illustration" src="assets/illu-pickup_object.png" width="100%" alt="Task illustration">
        </div>

        <div class="column has-text-centered" style="margin-top: 1rem;">
          Demonstration of task 
            <div class="select is-small">     
              <select id="demo-task" onchange="UpdateTaskDemonstration()">
              <option value="pickup_object" selected="selected">Pickup Object</option>
              <option value="close_drawer">Close Drawer</option>
              <option value="open_cabinet">Open Cabinet</option>
              <option value="transfer_water">Transfer Water</option>
              </select>
            </div>
            <br/>
            <br/>
  
            <video id="task-demonstration"
                    muted
                    autoplay
                    loop
                    width="100%">
              <source src="assets/demo-pickup_object.mp4"
                      type="video/mp4">
            </video>
        </div>

      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-widescreen content">
    <h2 class="title">BibTeX</h2>
    <pre><code>Placeholder</code></pre>
  </div>
</section>


</body>
</html>
